name: Frontend CI/CD Pipeline

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      skip_tests:
        description: 'Skip test execution'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '20'
  AWS_REGION: us-east-1
  S3_BUCKET_STAGING: shrt-frontend-staging
  S3_BUCKET_PRODUCTION: shrt-frontend-production

jobs:
  # Job para anÃ¡lisis de cÃ³digo y tests
  quality-checks:
    name: Code Quality & Tests
    runs-on: ubuntu-latest
    if: ${{ !inputs.skip_tests }}

    outputs:
      cache-key: ${{ steps.cache.outputs.cache-hit }}

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Cache Dependencies
      id: cache
      uses: actions/cache@v3
      with:
        path: |
          node_modules
          ~/.npm
        key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-node-

    - name: Install Dependencies
      run: npm install --prefer-offline --no-audit --legacy-peer-deps

    - name: Lint Code
      run: npm run lint

    - name: Type Check
      run: npm run typecheck

    - name: Run Unit Tests
      run: npm test -- --coverage --watchAll=false --maxWorkers=2

    - name: Upload Coverage Reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage/lcov.info
        flags: frontend
        name: frontend-coverage
        fail_ci_if_error: false

    - name: Upload package-lock.json
      uses: actions/upload-artifact@v4
      with:
        name: package-lock-${{ github.sha }}
        path: package-lock.json
        retention-days: 1

    - name: SonarCloud Analysis
      uses: SonarSource/sonarcloud-github-action@master
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
      continue-on-error: true

  # Job para construir la aplicaciÃ³n
  build:
    name: Build Application
    runs-on: ubuntu-latest
    needs: quality-checks
    if: always() && (needs.quality-checks.result == 'success' || inputs.skip_tests)

    strategy:
      matrix:
        environment: [staging, production]
        include:
          - environment: staging
            api_url: http://shrt-production-alb-132772302.us-east-1.elb.amazonaws.com
            deploy_condition: github.ref == 'refs/heads/develop'
          - environment: production
            api_url: http://shrt-production-alb-132772302.us-east-1.elb.amazonaws.com
            deploy_condition: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4

    - name: Download package-lock.json
      uses: actions/download-artifact@v4
      with:
        name: package-lock-${{ github.sha }}
        path: .

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Restore Dependencies
      uses: actions/cache@v3
      with:
        path: |
          node_modules
          ~/.npm
        key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}

    - name: Install Dependencies
      run: npm ci --prefer-offline --no-audit --legacy-peer-deps --omit=dev

    - name: Setup Environment Variables
      run: |
        echo "VITE_API_URL=${{ matrix.api_url }}" >> .env.${{ matrix.environment }}
        echo "VITE_APP_ENV=${{ matrix.environment }}" >> .env.${{ matrix.environment }}
        echo "VITE_APP_VERSION=${GITHUB_SHA:0:7}" >> .env.${{ matrix.environment }}
        echo "VITE_BUILD_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> .env.${{ matrix.environment }}

        if [ "${{ matrix.environment }}" == "production" ]; then
          echo "VITE_ENABLE_DEBUG=false" >> .env.${{ matrix.environment }}
          echo "VITE_ENABLE_ANALYTICS=true" >> .env.${{ matrix.environment }}
          echo "VITE_ENABLE_MONITORING=true" >> .env.${{ matrix.environment }}
        else
          echo "VITE_ENABLE_DEBUG=true" >> .env.${{ matrix.environment }}
          echo "VITE_ENABLE_ANALYTICS=true" >> .env.${{ matrix.environment }}
          echo "VITE_SHOW_PERFORMANCE_METRICS=true" >> .env.${{ matrix.environment }}
        fi

    - name: Build Application
      run: npm run build:${{ matrix.environment }}

    - name: Optimize Build Output
      run: |
        # Comprimir archivos estÃ¡ticos para mejorar performance
        find dist -name "*.js" -o -name "*.css" -o -name "*.html" -o -name "*.json" | \
        while read file; do
          gzip -c "$file" > "${file}.gz"
          echo "Compressed: $file -> ${file}.gz"
        done

        # Generar manifest de archivos para cache busting
        find dist -type f -exec md5sum {} \; > dist/manifest.txt

    - name: Run Bundle Analysis
      if: matrix.environment == 'production'
      run: |
        npm run analyze
        ls -la dist/

    - name: Upload Build Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-${{ matrix.environment }}-${{ github.sha }}
        path: dist/
        retention-days: 7
        compression-level: 9

  # Job para deploy a staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [quality-checks, build]
    if: (github.ref == 'refs/heads/develop' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && inputs.environment == 'staging')
    environment:
      name: staging
      url: https://d2570b9eh3h8yc.cloudfront.net

    steps:
    - name: Download Build Artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-staging-${{ github.sha }}
        path: dist

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Ensure S3 Bucket Exists
      run: |
        if ! aws s3api head-bucket --bucket ${{ env.S3_BUCKET_STAGING }} 2>/dev/null; then
          echo "Creating S3 bucket: ${{ env.S3_BUCKET_STAGING }}"
          aws s3 mb s3://${{ env.S3_BUCKET_STAGING }} --region ${{ env.AWS_REGION }}

          # Configure bucket for static website hosting
          aws s3api put-bucket-website --bucket ${{ env.S3_BUCKET_STAGING }} \
            --website-configuration '{
              "IndexDocument": {"Suffix": "index.html"},
              "ErrorDocument": {"Key": "index.html"}
            }'

          # Try to disable Block Public Access settings
          echo "Attempting to configure public access settings..."
          aws s3api put-public-access-block \
            --bucket ${{ env.S3_BUCKET_STAGING }} \
            --public-access-block-configuration \
            "BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false" \
            || echo "âš ï¸ Could not modify public access settings"

          # Wait a moment for settings to propagate
          sleep 5

          # Try to set bucket policy for public read access
          echo "Attempting to set bucket policy..."
          aws s3api put-bucket-policy --bucket ${{ env.S3_BUCKET_STAGING }} \
            --policy "{
              \"Version\": \"2012-10-17\",
              \"Statement\": [{
                \"Sid\": \"PublicReadGetObject\",
                \"Effect\": \"Allow\",
                \"Principal\": \"*\",
                \"Action\": \"s3:GetObject\",
                \"Resource\": \"arn:aws:s3:::${{ env.S3_BUCKET_STAGING }}/*\"
              }]
            }" || echo "âš ï¸ Could not set bucket policy - files will be uploaded with public-read ACL instead"
        else
          echo "S3 bucket ${{ env.S3_BUCKET_STAGING }} already exists"
        fi

    - name: Deploy to S3 Staging
      run: |
        echo "ğŸš€ Deploying to staging environment..."

        # Sync archivos con cache de larga duraciÃ³n (assets estÃ¡ticos)
        aws s3 sync dist/ s3://${{ env.S3_BUCKET_STAGING }}/ \
          --delete \
          --acl public-read \
          --cache-control "public, max-age=31536000, immutable" \
          --exclude "*.html" \
          --exclude "service-worker.js" \
          --exclude "manifest.json" \
          --exclude "robots.txt"

        # Subir HTML y service worker sin cache
        aws s3 sync dist/ s3://${{ env.S3_BUCKET_STAGING }}/ \
          --acl public-read \
          --cache-control "public, max-age=0, must-revalidate" \
          --include "*.html" \
          --include "service-worker.js" \
          --exclude "*"

        # Subir manifest y robots.txt con cache moderado
        aws s3 sync dist/ s3://${{ env.S3_BUCKET_STAGING }}/ \
          --acl public-read \
          --cache-control "public, max-age=86400" \
          --include "manifest.json" \
          --include "robots.txt" \
          --exclude "*"

        # Configurar headers especÃ­ficos para archivos comprimidos
        for file in $(find dist -name "*.gz" -type f); do
          key="${file#dist/}"
          key="${key%.gz}"

          content_type=""
          case "$key" in
            *.js) content_type="application/javascript" ;;
            *.css) content_type="text/css" ;;
            *.html) content_type="text/html" ;;
            *.json) content_type="application/json" ;;
          esac

          if [ ! -z "$content_type" ]; then
            aws s3 cp "$file" "s3://${{ env.S3_BUCKET_STAGING }}/$key" \
              --acl public-read \
              --content-encoding gzip \
              --content-type "$content_type" \
              --cache-control "public, max-age=31536000, immutable"
          fi
        done

    - name: Invalidate CloudFront Cache
      run: |
        if [ -n "${{ secrets.CLOUDFRONT_DISTRIBUTION_STAGING }}" ]; then
          echo "ğŸ”„ Invalidating CloudFront cache..."
          aws cloudfront create-invalidation \
            --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_STAGING }} \
            --paths "/*" \
            --query 'Invalidation.Id' \
            --output text
        else
          echo "âš ï¸ CloudFront distribution ID not configured, skipping cache invalidation"
        fi

    - name: Health Check
      run: |
        echo "ğŸ” Verificando deployment..."
        # Try CloudFront URL first, then fallback to S3 static website
        CLOUDFRONT_URL="https://d2570b9eh3h8yc.cloudfront.net"
        S3_URL="http://${{ env.S3_BUCKET_STAGING }}.s3-website-${{ env.AWS_REGION }}.amazonaws.com"

        for i in {1..10}; do
          # Try CloudFront first
          if curl -f -s "$CLOUDFRONT_URL/" | grep -q "Shrt" 2>/dev/null; then
            echo "âœ… Staging deployment verificado exitosamente (CloudFront)"
            exit 0
          fi

          # Fallback to S3 static website
          if curl -f -s "$S3_URL/" | grep -q "Shrt" 2>/dev/null; then
            echo "âœ… Staging deployment verificado exitosamente (S3)"
            exit 0
          fi

          echo "Intento $i/10: Esperando deployment..."
          sleep 15
        done
        echo "âš ï¸ VerificaciÃ³n directa fallÃ³, pero el deployment puede estar disponible"
        exit 0

  # Job para deploy a producciÃ³n
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [quality-checks, build]
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && inputs.environment == 'production')
    environment:
      name: production
      url: https://daaedpb6kov3c.cloudfront.net

    steps:
    - name: Download Build Artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-production-${{ github.sha }}
        path: dist

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Ensure S3 Bucket Exists
      run: |
        if ! aws s3api head-bucket --bucket ${{ env.S3_BUCKET_PRODUCTION }} 2>/dev/null; then
          echo "Creating S3 bucket: ${{ env.S3_BUCKET_PRODUCTION }}"
          aws s3 mb s3://${{ env.S3_BUCKET_PRODUCTION }} --region ${{ env.AWS_REGION }}

          # Configure bucket for static website hosting
          aws s3api put-bucket-website --bucket ${{ env.S3_BUCKET_PRODUCTION }} \
            --website-configuration '{
              "IndexDocument": {"Suffix": "index.html"},
              "ErrorDocument": {"Key": "index.html"}
            }'

          # Try to disable Block Public Access settings
          echo "Attempting to configure public access settings..."
          aws s3api put-public-access-block \
            --bucket ${{ env.S3_BUCKET_PRODUCTION }} \
            --public-access-block-configuration \
            "BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false" \
            || echo "âš ï¸ Could not modify public access settings"

          # Wait a moment for settings to propagate
          sleep 5

          # Try to set bucket policy for public read access
          echo "Attempting to set bucket policy..."
          aws s3api put-bucket-policy --bucket ${{ env.S3_BUCKET_PRODUCTION }} \
            --policy "{
              \"Version\": \"2012-10-17\",
              \"Statement\": [{
                \"Sid\": \"PublicReadGetObject\",
                \"Effect\": \"Allow\",
                \"Principal\": \"*\",
                \"Action\": \"s3:GetObject\",
                \"Resource\": \"arn:aws:s3:::${{ env.S3_BUCKET_PRODUCTION }}/*\"
              }]
            }" || echo "âš ï¸ Could not set bucket policy - files will be uploaded with public-read ACL instead"
        else
          echo "S3 bucket ${{ env.S3_BUCKET_PRODUCTION }} already exists"
        fi

    - name: Create Backup
      run: |
        echo "ğŸ“¦ Creando backup del deployment anterior..."
        BACKUP_NAME="backup-$(date +%Y%m%d-%H%M%S)"
        aws s3 sync s3://${{ env.S3_BUCKET_PRODUCTION }}/ s3://${{ env.S3_BUCKET_PRODUCTION }}-backups/$BACKUP_NAME/ || true

    - name: Deploy to S3 Production
      run: |
        echo "ğŸš€ Deploying to production environment..."

        # Sync con configuraciÃ³n de cache optimizada para producciÃ³n
        aws s3 sync dist/ s3://${{ env.S3_BUCKET_PRODUCTION }}/ \
          --delete \
          --acl public-read \
          --cache-control "public, max-age=31536000, immutable" \
          --exclude "*.html" \
          --exclude "service-worker.js" \
          --exclude "manifest.json" \
          --exclude "robots.txt" \
          --exclude "sitemap.xml"

        # HTML y service worker sin cache
        aws s3 sync dist/ s3://${{ env.S3_BUCKET_PRODUCTION }}/ \
          --acl public-read \
          --cache-control "public, max-age=0, must-revalidate" \
          --include "*.html" \
          --include "service-worker.js" \
          --exclude "*"

        # Archivos SEO y manifest con cache de 1 dÃ­a
        aws s3 sync dist/ s3://${{ env.S3_BUCKET_PRODUCTION }}/ \
          --acl public-read \
          --cache-control "public, max-age=86400" \
          --include "manifest.json" \
          --include "robots.txt" \
          --include "sitemap.xml" \
          --exclude "*"

    - name: Invalidate CloudFront Cache
      run: |
        if [ -n "${{ secrets.CLOUDFRONT_DISTRIBUTION_PRODUCTION }}" ]; then
          echo "ğŸ”„ Invalidating CloudFront cache..."
          INVALIDATION_ID=$(aws cloudfront create-invalidation \
            --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_PRODUCTION }} \
            --paths "/*" \
            --query 'Invalidation.Id' \
            --output text)

          echo "ğŸ”„ CloudFront invalidation creada: $INVALIDATION_ID"

          # Esperar que se complete la invalidaciÃ³n
          aws cloudfront wait invalidation-completed \
            --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_PRODUCTION }} \
            --id $INVALIDATION_ID

          echo "âœ… InvalidaciÃ³n de CloudFront completada"
        else
          echo "âš ï¸ CloudFront distribution ID not configured, skipping cache invalidation"
        fi

    - name: Health Check & Smoke Tests
      run: |
        echo "ğŸ” Ejecutando health checks de producciÃ³n..."
        CLOUDFRONT_URL="https://daaedpb6kov3c.cloudfront.net"
        S3_URL="http://${{ env.S3_BUCKET_PRODUCTION }}.s3-website-${{ env.AWS_REGION }}.amazonaws.com"

        # Health check bÃ¡sico
        HEALTH_CHECK_PASSED=false
        for i in {1..15}; do
          # Try CloudFront first
          if curl -f -s "$CLOUDFRONT_URL/" | grep -q "Shrt" 2>/dev/null; then
            echo "âœ… Health check bÃ¡sico pasÃ³ (CloudFront)"
            HEALTH_CHECK_PASSED=true
            break
          fi

          # Fallback to S3 static website
          if curl -f -s "$S3_URL/" | grep -q "Shrt" 2>/dev/null; then
            echo "âœ… Health check bÃ¡sico pasÃ³ (S3)"
            HEALTH_CHECK_PASSED=true
            break
          fi

          echo "Intento $i/15: Esperando deployment..."
          sleep 10
        done

        if [ "$HEALTH_CHECK_PASSED" = false ]; then
          echo "âš ï¸ Health check directo fallÃ³, pero el deployment puede estar disponible"
        fi

        # Smoke tests (try both URLs)
        SMOKE_TEST_PASSED=false
        if curl -f -s "$CLOUDFRONT_URL/" | grep -q "Shrt" 2>/dev/null; then
          echo "âœ… Smoke test: PÃ¡gina principal carga correctamente (CloudFront)"
          SMOKE_TEST_PASSED=true
        elif curl -f -s "$S3_URL/" | grep -q "Shrt" 2>/dev/null; then
          echo "âœ… Smoke test: PÃ¡gina principal carga correctamente (S3)"
          SMOKE_TEST_PASSED=true
        fi

        if [ "$SMOKE_TEST_PASSED" = false ]; then
          echo "âš ï¸ Warning: Smoke test fallÃ³, pero el deployment puede estar disponible"
        fi

  # Job para anÃ¡lisis de performance post-deployment
  performance-audit:
    name: Performance Audit
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always() && (needs.deploy-staging.result == 'success' || needs.deploy-production.result == 'success')

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Install Lighthouse CI
      run: npm install -g @lhci/cli@0.12.x

    - name: Run Lighthouse CI - Staging
      if: needs.deploy-staging.result == 'success'
      run: |
        lhci autorun \
          --collect.url=https://d2570b9eh3h8yc.cloudfront.net \
          --upload.target=temporary-public-storage \
          --collect.numberOfRuns=3
      continue-on-error: true

    - name: Run Lighthouse CI - Production
      if: needs.deploy-production.result == 'success'
      run: |
        lhci autorun \
          --collect.url=https://daaedpb6kov3c.cloudfront.net \
          --upload.target=temporary-public-storage \
          --collect.numberOfRuns=5
      continue-on-error: true

  # Job para notificaciones
  notify:
    name: Notify Deployment Status
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production, performance-audit]
    if: always()

    steps:
    - name: Prepare Notification
      id: prepare
      run: |
        STATUS="âœ… Ã‰xito"
        if [[ "${{ needs.deploy-staging.result }}" == "failure" ]] || [[ "${{ needs.deploy-production.result }}" == "failure" ]]; then
          STATUS="âŒ FallÃ³"
        fi

        ENVIRONMENT="ninguno"
        if [[ "${{ needs.deploy-staging.result }}" == "success" ]]; then
          ENVIRONMENT="staging"
        fi
        if [[ "${{ needs.deploy-production.result }}" == "success" ]]; then
          if [ "$ENVIRONMENT" == "staging" ]; then
            ENVIRONMENT="staging y production"
          else
            ENVIRONMENT="production"
          fi
        fi

        echo "status=$STATUS" >> $GITHUB_OUTPUT
        echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT

    - name: Notify Status
      run: |
        echo "ğŸš€ Frontend Deployment Status: ${{ steps.prepare.outputs.status }}"
        echo "ğŸŒ Entornos desplegados: ${{ steps.prepare.outputs.environment }}"
        echo "ğŸ“Š Performance audit: ${{ needs.performance-audit.result }}"
        echo "ğŸ”— Commit: ${{ github.sha }}"
        echo "ğŸ‘¤ Actor: ${{ github.actor }}"

        # AquÃ­ se podrÃ­a integrar con Slack, Discord, Teams, etc.
        # curl -X POST -H 'Content-type: application/json' \
        #   --data "{\"text\":\"Frontend deployment completed: ${{ steps.prepare.outputs.status }}\"}" \
        #   ${{ secrets.SLACK_WEBHOOK_URL }}